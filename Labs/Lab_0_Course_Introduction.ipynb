{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 0: Course Introduction & Resources\n",
        "\n",
        "**Duration:** ~65 minutes\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction to Faculty & Course Overview\n",
        "\n",
        "### Meet Your Instructors\n",
        "\n",
        "#### **Ashwin**\n",
        "- Background and expertise\n",
        "- Research interests and industry experience\n",
        "- Office hours and contact information\n",
        "\n",
        "#### **Sparsh**\n",
        "- Background and expertise\n",
        "- Research interests and industry experience\n",
        "- Office hours and contact information\n",
        "\n",
        "---\n",
        "\n",
        "### Course Philosophy\n",
        "\n",
        "This course takes a **hands-on, implementation-first** approach to deep learning. Our goal is to help you:\n",
        "\n",
        "1. **Understand the fundamentals** â€” Build strong mathematical and conceptual foundations\n",
        "2. **Implement from scratch** â€” Write neural networks without hiding behind libraries\n",
        "3. **Apply to real problems** â€” Work on projects that matter\n",
        "4. **Stay current** â€” Learn the latest architectures and techniques\n",
        "\n",
        "---\n",
        "\n",
        "### Course Structure\n",
        "\n",
        "| Module | Topic | Duration |\n",
        "|--------|-------|----------|\n",
        "| 1 | Probability & Information Theory | 2 weeks |\n",
        "| 2 | Sequence Modeling (RNNs, LSTMs) | 2 weeks |\n",
        "| 3 | Applications (Vision, NLP, Scale) | 2 weeks |\n",
        "| 4 | Advanced Topics & Projects | Ongoing |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Reference Material Walkthrough\n",
        "\n",
        "### Core Textbooks\n",
        "\n",
        "#### **Deep Learning**\n",
        "*by Ian Goodfellow, Yoshua Bengio, and Aaron Courville*\n",
        "\n",
        "**Free Online:** [https://www.deeplearningbook.org/](https://www.deeplearningbook.org/)\n",
        "\n",
        "This is the definitive textbook for deep learning. Key chapters we'll reference:\n",
        "\n",
        "| Part | Chapters | Topics |\n",
        "|------|----------|--------|\n",
        "| I - Applied Math | 2-4 | Linear Algebra, Probability, Numerical Computation |\n",
        "| II - Deep Networks | 6-12 | MLPs, Regularization, Optimization, CNNs, RNNs |\n",
        "| III - Research | 13-20 | Autoencoders, Generative Models, Monte Carlo Methods |\n",
        "\n",
        "**Why this book?**\n",
        "- Written by pioneers of the field (Yoshua Bengio won the Turing Award)\n",
        "- Perfect balance of theory and intuition\n",
        "- Comprehensive coverage from basics to advanced\n",
        "\n",
        "---\n",
        "\n",
        "#### **Pattern Recognition and Machine Learning**\n",
        "*by Christopher M. Bishop*\n",
        "\n",
        "**PDF Available:** [Microsoft Research](https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/)\n",
        "\n",
        "The classic machine learning textbook with rigorous probabilistic foundations:\n",
        "\n",
        "| Chapter | Topics | Relevance |\n",
        "|---------|--------|-----------|\n",
        "| 1-2 | Introduction, Probability | Foundation for everything |\n",
        "| 3-4 | Linear Models | Building blocks |\n",
        "| 5 | Neural Networks | Core architectures |\n",
        "| 8-9 | Graphical Models | Probabilistic reasoning |\n",
        "| 13 | Sequential Data | RNNs and sequences |\n",
        "\n",
        "**Why this book?**\n",
        "- Gold standard for mathematical rigor\n",
        "- Beautiful visualizations and explanations\n",
        "- Bayesian perspective throughout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Video: Deep Learning Evolution\n",
        "\n",
        "---\n",
        "\n",
        "Before diving into the material, watch these videos to understand the historical context and evolution of deep learning:\n",
        "\n",
        "#### **Essential Viewing**\n",
        "\n",
        "| Video | Duration | Link |\n",
        "|-------|----------|------|\n",
        "| **MIT Introduction to Deep Learning** | ~1 hr | [YouTube](https://www.youtube.com/watch?v=ErnWZxJovaM) |\n",
        "| **Neural Networks: Zero to Hero** - Andrej Karpathy | Series | [Playlist](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) |\n",
        "| **But what is a neural network?** - 3Blue1Brown | ~19 min | [YouTube](https://www.youtube.com/watch?v=aircAruvnKk) |\n",
        "| **The Deep Learning Revolution** - Geoffrey Hinton | ~45 min | [YouTube](https://www.youtube.com/watch?v=VsnQf7exv5I) |\n",
        "| **How Deep Neural Networks Work** - Brandon Rohrer | ~26 min | [YouTube](https://www.youtube.com/watch?v=ILsA4nyG7I0) |\n",
        "\n",
        "#### **Recommended Timeline Understanding**\n",
        "\n",
        "```\n",
        "1943: McCulloch-Pitts Neuron\n",
        "1958: Perceptron (Frank Rosenblatt)\n",
        "1969: \"Perceptrons\" book â†’ AI Winter begins\n",
        "1986: Backpropagation popularized (Rumelhart, Hinton, Williams)\n",
        "1998: LeNet-5 (Yann LeCun) â†’ CNNs for digits\n",
        "2006: Deep Belief Networks (Hinton) â†’ Deep Learning renaissance\n",
        "2012: AlexNet wins ImageNet â†’ GPU revolution begins\n",
        "2014: GANs introduced (Goodfellow)\n",
        "2017: \"Attention Is All You Need\" â†’ Transformer era\n",
        "2020+: GPT-3, DALL-E, Foundation Models\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ“º YouTube Channels & Online Resources\n",
        "\n",
        "---\n",
        "\n",
        "#### **Foundations & Math**\n",
        "\n",
        "| Channel | Focus | Best For | Link |\n",
        "|---------|-------|----------|------|\n",
        "| **3Blue1Brown** | Visual math & intuition | Linear algebra, calculus, neural nets | [youtube.com/@3blue1brown](https://www.youtube.com/@3blue1brown) |\n",
        "| **Khan Academy** | Comprehensive fundamentals | Probability, statistics, calculus | [khanacademy.org](https://www.khanacademy.org/) |\n",
        "| **StatQuest (Josh Starmer)** | Statistics & ML basics | Breaking down complex stats simply | [youtube.com/@statquest](https://www.youtube.com/@statquest) |\n",
        "\n",
        "---\n",
        "\n",
        "#### **Building & Implementation**\n",
        "\n",
        "| Channel | Focus | Best For | Link |\n",
        "|---------|-------|----------|------|\n",
        "| **Andrej Karpathy** | From-scratch implementations | Building GPT, neural nets from zero | [youtube.com/@AndrejKarpathy](https://www.youtube.com/@AndrejKarpathy) |\n",
        "| **fast.ai (Jeremy Howard)** | Practical deep learning | Top-down learning approach | [youtube.com/@howardjeremyp](https://www.youtube.com/@howardjeremyp) |\n",
        "| **Sentdex** | Python ML tutorials | Hands-on coding projects | [youtube.com/@sentdex](https://www.youtube.com/@sentdex) |\n",
        "| **deeplizard** | PyTorch & TensorFlow | Step-by-step implementations | [youtube.com/@deeplizard](https://www.youtube.com/@deeplizard) |\n",
        "| **CodeEmporium** | Math to code | Implementing papers | [youtube.com/@CodeEmporium](https://www.youtube.com/@CodeEmporium) |\n",
        "| **Nicholas Renotte** | End-to-end projects | Building real ML applications | [youtube.com/@NicholasRenotte](https://www.youtube.com/@NicholasRenotte) |\n",
        "| **Abhishek Thakur** | Kaggle & applied ML | Competition-winning techniques | [youtube.com/@abhaborhis](https://www.youtube.com/@abhishekkrthakur) |\n",
        "\n",
        "---\n",
        "\n",
        "#### **Research & Cutting Edge**\n",
        "\n",
        "| Channel | Focus | Best For | Link |\n",
        "|---------|-------|----------|------|\n",
        "| **Yannic Kilcher** | Paper explanations | Understanding new research | [youtube.com/@YannicKilcher](https://www.youtube.com/@YannicKilcher) |\n",
        "| **Two Minute Papers** | Research summaries | Staying current with breakthroughs | [youtube.com/@TwoMinutePapers](https://www.youtube.com/@TwoMinutePapers) |\n",
        "| **The AI Epiphany** | Deep dives into architectures | Transformer implementations | [youtube.com/@TheAIEpiphany](https://www.youtube.com/@TheAIEpiphany) |\n",
        "| **Machine Learning Street Talk** | Expert interviews | Industry perspectives | [youtube.com/@MachineLearningStreetTalk](https://www.youtube.com/@MachineLearningStreetTalk) |\n",
        "| **AI Coffee Break with Letitia** | Paper walkthroughs | Digestible research explanations | [youtube.com/@AICoffeeBreak](https://www.youtube.com/@AICoffeeBreak) |\n",
        "\n",
        "---\n",
        "\n",
        "#### **Tools & Frameworks**\n",
        "\n",
        "| Channel | Focus | Best For | Link |\n",
        "|---------|-------|----------|------|\n",
        "| **Weights & Biases** | MLOps & experiment tracking | Production ML workflows | [youtube.com/@WeightsBiases](https://www.youtube.com/@WeightsBiases) |\n",
        "| **PyTorch** | Official tutorials | Framework deep dives | [youtube.com/@PyTorch](https://www.youtube.com/@PyTorch) |\n",
        "| **Hugging Face** | Transformers & NLP | Using pre-trained models | [youtube.com/@HuggingFace](https://www.youtube.com/@HuggingFace) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Additional Reading\n",
        "\n",
        "---\n",
        "\n",
        "#### **Papers Everyone Should Read**\n",
        "\n",
        "1. **ImageNet Classification with Deep CNNs** (AlexNet, 2012)\n",
        "   - The paper that started the deep learning revolution\n",
        "   \n",
        "2. **Attention Is All You Need** (2017)\n",
        "   - Introduced the Transformer architecture\n",
        "   \n",
        "3. **Deep Residual Learning** (ResNet, 2015)\n",
        "   - Skip connections that enabled very deep networks\n",
        "   \n",
        "4. **Generative Adversarial Networks** (2014)\n",
        "   - Revolutionary approach to generative modeling\n",
        "\n",
        "5. **BERT: Pre-training of Deep Bidirectional Transformers** (2018)\n",
        "   - Changed NLP forever\n",
        "\n",
        "---\n",
        "\n",
        "#### **Blogs & Websites**\n",
        "\n",
        "| Resource | Focus | Link |\n",
        "|----------|-------|------|\n",
        "| **Distill.pub** | Beautiful ML explanations | [distill.pub](https://distill.pub/) |\n",
        "| **Lil'Log** | Comprehensive tutorials | [lilianweng.github.io](https://lilianweng.github.io/) |\n",
        "| **Jay Alammar's Blog** | Visual explanations | [jalammar.github.io](https://jalammar.github.io/) |\n",
        "| **Papers With Code** | Papers + implementations | [paperswithcode.com](https://paperswithcode.com/) |\n",
        "| **Colah's Blog** | Intuitive explanations | [colah.github.io](https://colah.github.io/) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting Started Checklist\n",
        "\n",
        "---\n",
        "\n",
        "Before the next session, please complete:\n",
        "\n",
        "- [ ] **Bookmark** the Deep Learning book website\n",
        "- [ ] **Watch** at least one 3Blue1Brown neural network video\n",
        "- [ ] **Subscribe** to 2-3 channels from the list above\n",
        "- [ ] **Skim** Chapter 1 of the Deep Learning book\n",
        "- [ ] **Set up** your Python environment (Jupyter, PyTorch/TensorFlow)\n",
        "\n",
        "---\n",
        "\n",
        "### Questions?\n",
        "\n",
        "Reach out to **Ashwin** or **Sparsh** during office hours or via the course communication channels.\n",
        "\n",
        "---\n",
        "\n",
        "*Welcome to the deep learning journey! ðŸ§ *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
